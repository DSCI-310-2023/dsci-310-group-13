# Predicting Youtube View Count in 2007/2008

### Introduction

After being acquired by Google in 2006, Youtube obtained a rapid growth in popularity resulting in a growing community. The goal of this project is to use the data of 2007 to predict the view of videos in 2008. We will be using datasets from https://netsg.cs.sfu.ca/youtubedata/. 


### Methods

```{r, message=FALSE,warning=FALSE, include=TRUE, echo=FALSE}
# Setup
library(tidyverse)
library(tidymodels)
library(corrplot)
library(car)
library(leaps)
library(testthat)
```

```{r, message=FALSE, include=TRUE, echo=FALSE}
# Load the functions
source("/home/rstudio/R/functions.R")
```

#### Wrangling data
We decide to immediately remove some of the variables presented in the datasets. This included `uploader`,`video ID`, and `related IDs` because these variables appear to be unique to the videos itself and not affect video views as a whole.

```{r, include=TRUE, echo=FALSE}
#load the cleaned datasets
data2007 = read.delim("/home/rstudio/data/data2007_cleaned.txt", 
                      sep = "\t", dec = ".", header = TRUE)
data2008 = read.delim("/home/rstudio/data/data2008_cleaned.txt", 
                      sep = "\t", dec = ".", header = TRUE)
head(data2007)
```

**Table 1:** The dataset obtained uses a crawler to obtained video API and scrape the webpage for the remaining information.
\
\

**Features: **
\
\
**-Age:** an integer number of days between the date when the video was uploaded and Feb.15, 2007

**-Category:** string of the video category chosen by the uploader

**-Length:** integer number of the video length

**-Views:** integer number of the views

**-Rate:** float number of the video rate

**-Ratings:** integer number of the ratings

**-Comments:** integer number of the comments
\
\

### Preliminary Analysis

```{r, include=TRUE, echo=FALSE}
knitr::include_graphics("/home/rstudio/output/figure_1.png")
```

**Figure 1:** Plot of `views` against the quantitative explanatory variables

We can observe that most variables do not a have linear relationship with the predictor variable, only `ratings` has a slight positive linear relationship. Some variables like `length` and `comments` may benefit from a logarithmic transformation.

```{r, include=TRUE, echo=FALSE}
knitr::include_graphics("/home/rstudio/output/figure_2.png")
```

**Figure 2:** Plot of the number of views garnered by each type of category.
\
\

```{r, include=TRUE, echo=FALSE}
knitr::include_graphics("/home/rstudio/output/figure_3.png")
```

**Figure 3:** Correlation plot of the predictor and the explanatory variables, excluding `category`

Taking a look at the correlation plot, we can see that `ratings` and `comments` have the strong positive relationship with the predictive variable `views`. Meanwhile, the other explanatory variables have a very weak relationship with `views`. `ratings` has a positive correlation with `view` and `comments` too. Because there are explanatory variables with correlation against each other, we check if multicollinearity is significant by taking a look at the VIF scores.

```{r, include=TRUE, echo=FALSE}
vif(lm(views~.,data2007))
```

**Table 2:** VIF values of the explanatory variables

The VIF values of the variables are not particularly big, so multicollinearity would not affect the model significantly. 
\
\
### Model Selection

```{r, include=TRUE, echo=FALSE}
# Find the best model for each size
bestmod <- regsubsets(views~.,data2007,method='exhaustive')
summary(bestmod)
```
\
\
Looking at the selection algorithm, variables like `age`. `ratings`, and `comments` appear in most subsets. On the other hand, `category` did not appear consistently in the subsets, while `length` and `rate` were present in half of the displayed subsets.
\
\
```{r, include=TRUE, echo=FALSE}
knitr::include_graphics("/home/rstudio/output/figure_4.png")
```

**Figure 4:** Plot of the adjusted $R^2$ and BIC values against the size of the models
\
\
A well-fitted model would have a high adjusted $R^2$ and low BIC values, but these metrics are not particularly prioritized because our end goal is prediction, so we rather prioritize reducing RMSE. However, this figure suggests a large model would fit well with the data.

### Analysis

We choose to use 2 explanatory variables: `age` and `ratings` to predict our response variable. While having a larger model would fit our data better, we hope that minimizing the number of explanatory variables will reduce RMSE.

```{r, include=TRUE, echo=FALSE}
# Selecting variables for reduced model
datareduced <- data2007 |>  select(c(views,age,ratings,comments))
```

```{r, include=TRUE, echo=FALSE}
# Split data into training and testing set
split <- initial_split(datareduced, prop = 3/4, strata = views)
train <- training(split)
test <- testing(split)

# Fit the regression model
lm_fit <- fit_regression(train)
lm_fit
```
\
Although there is a low p-value for the coefficients, the adjusted R-squared value is not particularly high and an extremely high standard error.
\
```{r, include=TRUE, echo=FALSE}
# Lets look at how well our model performed
lm_test_results <- lm_fit |> predict(test) |> bind_cols(test) |> metrics(truth = views, estimate = .pred)

lm_test_results
```
\
It seems like the residual mean squared error is still enormously high, but the RMSE is smaller than that of the full model.
\
```{r, include=TRUE, echo=FALSE}
# Lets see if our model can predict the 2008 values well
data2008reduced <- data2008 |> select(c(age,ratings,comments))
predict2008 <- predict(lm_fit,data2008reduced)
head(cbind('Actual' = data2008$views,'Predicted' = predict2008))
```
\
Our predicted values are several times higher than the actual 2008 values.
